## 1.1 Introduction - The Challenger Case

The Case: Challenger Space Shuttle Explosion

**Cause**
- Rubber sealing ring (O-ring) failed at low temperatures → fuel leak → explosion.  

**What happened**
- Jan 1985: Engineer Roger Boisjoly (Morton Thiokol) raised doubts.  
- July 1985: Sent confidential memo.  
- Investigation group lacked sufficient resources.  
- On launch day: Company warned of risks, noted O-rings never tested below zero.  
- Opponents of launch had to *prove* it was unsafe.  
- Final decision driven by political & financial considerations.  

**What changed after**
- System reform for transparency & whistle-blowing.  
- Engineers gained more say.  

**Conclusion**  
The disaster was caused by technical error and inadequate communication.

---

## 1.2 Responsibility

- **Active Responsibility**: Duty before something happens (to care for sb./sth).  
- **Passive Responsibility**: After something has happened.  
- **Role Responsibility**: Based on one’s role in a context.  
- **Moral Responsibility**: Arises from moral norms, extends beyond roles, limits role duties.  
- **Professional Responsibility**: Responsibility in professional practice.  

---

## 1.3 Passive Responsibility

### ==Accountability==: 
Obligation to account for actions & consequences.  

### ==Blameworthiness==: 
- **==Wrongdoing==**: legal or organisational norms.  
- **==Causal Contribution==**: Failure to act can also cause harm; often part of causal chain.  
- **==Foreseeability==**: Whether consequences could be predicted.  
- **==Freedom of Action==**: If personal consequences limited freedom, responsibility may be reduced.  

---

## 1.4 Active Responsibility and the Ideals of Engineers
### ==Active Responsibility==:
  - Avoid undesired consequences.  
  - Realise positive consequences.  

### ==Professional Ideals==:
1. **==Technological Enthusiasm**==  
   - Example: Google Earth.  
   - Risk: Negative effects & social constraints overlooked.  
   - Wernher von Braun: Joined SS to continue rocket work.  

2. **==Effectiveness and Efficiency**==  
   - Effectiveness = goal achievement.  
   - Efficiency = ratio of achievement to effort.  
   - Taylorism (Frederick W. Taylor).  
   - Moral value depends on purpose.  

3. **==Human Welfare**==  
   - Values: health, environment, sustainability, safety.  
   - Example: Johan van Veen – father of Delta Works.  

---

## 1.5 Engineers versus Managers

### ==Models of Conflict==
1. ==**Separatism**== – Tripartite model; engineers as “hired guns.”  
2. **==Technocracy**== – Engineers as technocrats (risk: undemocratic, paternalistic).  
3. **==Whistle-blowing==** – Sacrifices required, effectiveness limited.  

### Constructive Approach:
- Engineers should recognize moral issues and discuss them constructively with other parties.  

---

## 1.6 The Social Context of Technological Development

### Actors:
- Developers & producers of technology
- Users
- Regulators
- Actor with certain interests (associations...)
- ==Stakeholders==: become actors / Important from moral perspective.  

*Examples*: Teflon: Once widely used, later suspected carcinogenic.  
Therefore,
### ==Technology Assessment== (TA)
- Hard to predict consequences.  
- Once embedded in society, technology is “locked in” → *Collingridge dilemma*.  

### ==Constructive Technology Assessment== (CTA)
- TA carried out alongside technology development and give feedback into design.  
- Involving multiple actors reduces engineers’ sole responsibility.  
- Stakeholders gain larger say.  

---

# Chapter 1: Q&A

## 1. What are the five features of active responsibility according to Bovens?

According to Bovens, the five features of active responsibility are:
- Adequate **perception** of threatened violations of norms
- **Consideration** of the consequences
- **Autonomy**, i.e., the ability to make one’s own independent moral decisions
- Displaying conduct that is based on a verifiable and **consistent** code
- Taking **role obligations** seriously

---

## 2. What is the difference between passive and active responsibility?

- **Passive responsibility**: Responsibility *after* something (usually undesirable) has happened. It involves being held accountable and possibly blameworthy for past actions or their consequences.
- **Active responsibility**: Responsibility *before* something happens. It involves a duty to act to prevent harm and promote positive outcomes, guided by virtues and professional ideals.

---

## 3. a. What criteria (conditions) are usually applied when deciding whether someone is passively responsible (blameworthy) for a certain action and its consequences?  

The four conditions for blameworthiness are:
- Wrong-doing (violation of a norm)
- Causal contribution (action/inaction contributed to the outcome)
- Foreseeability (could have known the consequences)
- Freedom of action (not coerced)

## 3.b. Suppose one person's actions have led to the injury of another person. What additional criteria must be satisfied in order to imply that the first person is passively responsible for the injury?

For the person to be held passively responsible for the injury, the following must also be true:
- The action violated a norm (e.g., safety standard or moral rule).
- The person made a causal contribution to the injury.
- The injury was foreseeable.
- The person acted freely (without coercion).

---

## 4. Do you consider Morton Thiokol responsible for the Challenger disaster? Refer to the criteria for responsibility.

Yes, Morton Thiokol can be considered responsible based on the four criteria:
- Wrong-doing: Violated NASA’s safety policy by reversing the burden of proof and ignoring engineers’ recommendations.
- Causal contribution: Their approval directly contributed to the launch and subsequent disaster.
- Foreseeability: They were aware of the O-ring risks at low temperatures.
- Freedom: They were under pressure but not coerced; they could have refused to approve.

---

## 5. Scenario: Engineer used wrong software, plane crashed. Do you consider this engineer responsible for the plane crash and the death of four people?

The engineer may be blameworthy if:
- Wrong-doing: Using inappropriate software violated professional standards.
- Causal contribution: The flawed design directly caused the crash.
- Foreseeability: The engineer should have known the software was unsuitable.
- Freedom: The engineer was not forced to use that software.

However, if the error was discovered *after* the crash, foreseeability may not be fully met. More information is needed about whether the engineer should have known earlier.

---

## 6. Give an example of moral responsibility in engineering and explain how it extends beyond role responsibility.

Example: An engineer designing a social media algorithm that increases engagement but spreads misinformation.

Moral responsibility involves considering broader societal impacts like truth and harm prevention, even beyond their role responsibility (which may only include technical performance and employer loyalty).

---

## 7. Describe three problems for engineers taking responsibility for technologies, with examples.

1. Hierarchical pressure: Engineers may be overruled by managers.  
   *Example*: Boisjoly in the Challenger case.

2. Unforeseen consequences: Technologies may have unintended effects.  
   *Example*: Teflon, initially a coolant, later found potentially carcinogenic.

3. Limited influence: Engineers are part of a larger system.  
   *Example*: Van Veen could not prevent the Dutch flood disaster alone due to organizational silence.

---

## 8. Explain 'separatism' and why the tripartite model illustrates it well.

Separatism: The idea that engineers should handle only technical inputs, while managers and politicians make value-based decisions.

The tripartite model illustrates this by dividing responsibility into:
- Managers/politicians (set goals)
- Engineers (design and execute)
- Users (passive recipients)

This confines engineers’ responsibility to technical matters only.

---

## 9. Why is it so difficult to steer technological development?

Technological development is hard to steer due to:
- Multiple actors with conflicting interests
- Unpredictability (e.g., accidental inventions like Teflon)
- The Collingridge dilemma: Once embedded, technologies are hard to change.

---

## 10. Why is 'public welfare' the most important ideal for engineers?

Public welfare is inherently morally commendable and aligns with core ethical values like safety, health, and sustainability. Unlike technological enthusiasm or efficiency, which can be misused, public welfare reflects the ethical heart of engineering.

---

## 11. Example of technological enthusiasm in your field and its moral characterization.

Example: Enthusiasm for plastic pyrolysis (converting waste plastic to fuel).  

The technical drive to solve plastic pollution is commendable. However, the process often lead to create more pollution (toxic emissions, low-quality fuel) or enables greenwashing, which makes it reprehensible. The morality depends on whether engineers prioritize a truly circular solution over a technically exciting but flawed one.